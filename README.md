**Toxicity Detection**

Toxicity Detection is a machine learning project designed to identify toxic comments using Natural Language Processing techniques. The project uses the Toxic Comment Classification Challenge dataset from Kaggle.

Overview:
The project's goal is to create a model capable of classifying user comments based on their toxicity levels. It involves building a multi-label classification model that can categorize comments into various toxicity categories such as toxic, severe toxic, obscene, threat, insult, and identity hate. A Streamlit app is also included to interactively check the toxicity of user-provided comments.

Requirements:

Python 3.x

TensorFlow 2.x
